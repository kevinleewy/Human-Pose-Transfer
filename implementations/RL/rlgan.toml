title = "PG2"

description = """
first try
"""

[dataset]
    name = "market"
    [dataset.path.train]
        image = "./data/Market-1501/bounding_box_train/"
        bone = "./data/market/train/pose_map_image/"
        mask = "./data/market/train/pose_mask_image/"
        pair = "./data/market/pairs-train.csv"
        annotation = "./data/market/annotation-train.csv"
    [dataset.path.test]
        image = "./data/Market-1501/bounding_box_test/"
        bone = "./data/market/test/pose_map_image/"
        mask = "./data/market/test/pose_mask_image/"
        pair = "./data/market/pairs-test.csv"
        annotation = "./data/market/annotation-test.csv"

[loss]
    [loss.mask_l1]
        weight = 10
        mask_ratio = 1
    [loss.gan]
        weight = 1

[model]
    [model.generator1]
        num_repeat = 5
        middle_features_dim = 64
        channels_base = 128
        image_size = [128, 64]
        # select the G1 path
        pretrained_path = "./checkpoints/PG2-1/network_G1_22000.pth"
    [model.generator2]
        weight_init_way = "xavier"
        num_skip_out_connect = 1
        num_repeat = 3
        channels_base = 128
        # only used when generating images.
        pretrained_path = "./checkpoints/PG2-2/network_G2_14000.pth"
    [model.discriminator]
        # tflib means the way used in author of paper's code.
        weight_init_way = "tflib"
    [model.lgan]
        max_action = 10
        model = "sagan"
        adv_loss = "wgan-gp"
        imsize = 32
        g_num = 5
        z_dim = 1
        g_conv_dim = 64
        d_conv_dim = 64
        pretrained_D = "./checkpoints/LGAN-PG2/models/sagan-1/947540_D.pth"
        pretrained_G = "./checkpoints/LGAN-PG2/models/sagan-1/947540_G.pth"
    [model.rl]
        attempts = 5
        policy_name = "DDPG"
        env_name = "RLGAN"
        state_dim = 196608
        max_action = 10
        k1 = 0.01
        k2 = 1.0
        k3 = 10
        k4 = 0.1
        pretrained_path = "./checkpoints/RL-GAN-PG2"
        

[train]
    batch_size = 1
    num_epoch = 1
    num_workers = 8
    start_timesteps = 10000
    eval_freq = 100000
    max_timesteps = 1000000
    save_models = 1
    batch_size_actor = 100
    discount = 0.99
    tau = 0.005
    expl_noise = 0.1
    policy_noise = 0.2
    noise_clip = 0.5
    policy_freq = 2
    max_episodes_steps = 5
    [train.data]
        replacement = false
        flip_rate = 0.5
    [train.generator2]
        lr = 0.00002
        beta1 = 0.5
        beta2 = 0.999
    [train.discriminator]
        lr = 0.00002
        beta1 = 0.5
        beta2 = 0.999

[log]
    loss_freq = 50
    check_freq = 10000
    [log.model_checkpoint]
        n_saved = 15
        save_interval = 1000
    [log.verify]
        batch_size = 16
        shuffle = true
